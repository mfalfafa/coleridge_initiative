{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cleared-messaging",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-22T02:49:37.134969Z",
     "iopub.status.busy": "2021-06-22T02:49:37.134410Z",
     "iopub.status.idle": "2021-06-22T02:50:12.105920Z",
     "shell.execute_reply": "2021-06-22T02:50:12.105301Z",
     "shell.execute_reply.started": "2021-06-22T02:09:24.954522Z"
    },
    "papermill": {
     "duration": 35.002157,
     "end_time": "2021-06-22T02:50:12.106069",
     "exception": false,
     "start_time": "2021-06-22T02:49:37.103912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n",
    "!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n",
    "!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n",
    "!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl\n",
    "\n",
    "# !pip3 uninstall fsspec -y\n",
    "!pip install fsspec==2021.5.0\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equipped-picking",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:50:12.138847Z",
     "iopub.status.busy": "2021-06-22T02:50:12.137775Z",
     "iopub.status.idle": "2021-06-22T02:50:12.765186Z",
     "shell.execute_reply": "2021-06-22T02:50:12.764649Z",
     "shell.execute_reply.started": "2021-06-22T02:09:59.690301Z"
    },
    "papermill": {
     "duration": 0.645318,
     "end_time": "2021-06-22T02:50:12.765326",
     "exception": false,
     "start_time": "2021-06-22T02:50:12.120008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import glob\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "random.seed(123)\n",
    "np.random.seed(456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wireless-missouri",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:50:12.797353Z",
     "iopub.status.busy": "2021-06-22T02:50:12.796630Z",
     "iopub.status.idle": "2021-06-22T02:50:13.440210Z",
     "shell.execute_reply": "2021-06-22T02:50:13.439700Z",
     "shell.execute_reply.started": "2021-06-22T02:10:00.387984Z"
    },
    "papermill": {
     "duration": 0.661297,
     "end_time": "2021-06-22T02:50:13.440334",
     "exception": false,
     "start_time": "2021-06-22T02:50:12.779037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy my_seqeval.py to the working directory because the input directory is non-writable\n",
    "!cp /kaggle/input/coleridge-packages/my_seqeval.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "short-lawyer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:50:13.470635Z",
     "iopub.status.busy": "2021-06-22T02:50:13.469921Z",
     "iopub.status.idle": "2021-06-22T02:50:13.472816Z",
     "shell.execute_reply": "2021-06-22T02:50:13.472383Z",
     "shell.execute_reply.started": "2021-06-22T02:10:01.034843Z"
    },
    "papermill": {
     "duration": 0.019204,
     "end_time": "2021-06-22T02:50:13.472928",
     "exception": false,
     "start_time": "2021-06-22T02:50:13.453724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 64 # max no. words for each sentence.\n",
    "OVERLAP = 20 # if a sentence exceeds MAX_LENGTH, we split it to multiple sentences with overlapping\n",
    "\n",
    "MAX_SAMPLE = None # set a small number for experimentation, set None for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "responsible-floating",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:50:13.501468Z",
     "iopub.status.busy": "2021-06-22T02:50:13.500796Z",
     "iopub.status.idle": "2021-06-22T02:50:13.503623Z",
     "shell.execute_reply": "2021-06-22T02:50:13.503206Z",
     "shell.execute_reply.started": "2021-06-22T02:15:07.811725Z"
    },
    "papermill": {
     "duration": 0.018361,
     "end_time": "2021-06-22T02:50:13.503731",
     "exception": false,
     "start_time": "2021-06-22T02:50:13.485370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = '../input/coleridgeinitiative-show-us-the-data/train.csv'\n",
    "paper_train_folder = '../input/coleridgeinitiative-show-us-the-data/train'\n",
    "\n",
    "# train = pd.read_csv(train_path)\n",
    "# train = train[:MAX_SAMPLE]\n",
    "# print(f'No. raw training rows: {len(train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "laden-lending",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:50:13.531531Z",
     "iopub.status.busy": "2021-06-22T02:50:13.530897Z",
     "iopub.status.idle": "2021-06-22T02:50:13.533647Z",
     "shell.execute_reply": "2021-06-22T02:50:13.533238Z",
     "shell.execute_reply.started": "2021-06-22T02:15:08.187126Z"
    },
    "papermill": {
     "duration": 0.017783,
     "end_time": "2021-06-22T02:50:13.533763",
     "exception": false,
     "start_time": "2021-06-22T02:50:13.515980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = train.groupby('Id').agg({\n",
    "#     'pub_title': 'first',\n",
    "#     'dataset_title': '|'.join,\n",
    "#     'dataset_label': '|'.join,\n",
    "#     'cleaned_label': '|'.join\n",
    "# }).reset_index()\n",
    "\n",
    "# print(f'No. grouped training rows: {len(train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-houston",
   "metadata": {
    "papermill": {
     "duration": 0.012207,
     "end_time": "2021-06-22T02:50:13.558272",
     "exception": false,
     "start_time": "2021-06-22T02:50:13.546065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "retired-treaty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:50:13.586498Z",
     "iopub.status.busy": "2021-06-22T02:50:13.585830Z",
     "iopub.status.idle": "2021-06-22T02:50:13.588650Z",
     "shell.execute_reply": "2021-06-22T02:50:13.588201Z",
     "shell.execute_reply.started": "2021-06-22T02:10:13.097523Z"
    },
    "papermill": {
     "duration": 0.018237,
     "end_time": "2021-06-22T02:50:13.588751",
     "exception": false,
     "start_time": "2021-06-22T02:50:13.570514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "descending-jersey",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:50:13.623545Z",
     "iopub.status.busy": "2021-06-22T02:50:13.622855Z",
     "iopub.status.idle": "2021-06-22T02:50:13.725935Z",
     "shell.execute_reply": "2021-06-22T02:50:13.726375Z",
     "shell.execute_reply.started": "2021-06-22T02:39:25.779415Z"
    },
    "papermill": {
     "duration": 0.125114,
     "end_time": "2021-06-22T02:50:13.726553",
     "exception": false,
     "start_time": "2021-06-22T02:50:13.601439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp8 = pd.read_csv('../input/ci-ext-datasets-found-in-train-v2/train_ext_data.csv')\n",
    "tmp8['ext_cleaned_label'] = tmp8['ext_cleaned_label'].apply(lambda x: x.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "therapeutic-karaoke",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:50:13.760636Z",
     "iopub.status.busy": "2021-06-22T02:50:13.760046Z",
     "iopub.status.idle": "2021-06-22T02:50:14.081581Z",
     "shell.execute_reply": "2021-06-22T02:50:14.081032Z",
     "shell.execute_reply.started": "2021-06-22T02:39:26.085522Z"
    },
    "papermill": {
     "duration": 0.34168,
     "end_time": "2021-06-22T02:50:14.081716",
     "exception": false,
     "start_time": "2021-06-22T02:50:13.740036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14316/14316 [00:00<00:00, 125530.29it/s]\n"
     ]
    }
   ],
   "source": [
    "not_datasets = ['about', 'climatologists', 'control', 'exploration', 'defense', \n",
    "                'american community', 'american landscape', 'current population survey',\n",
    "                'gulf of maine', 'argonne national laboratory s greet', \n",
    "                'annual wholesale trade',\n",
    "                'bird conservation areas', 'bird incidental take', 'new housing', 'business patterns',\n",
    "                'create', 'federal aid to states', 'freedom of information act', 'fruit and vegetable prices',\n",
    "                'guidance navigation and control', 'high school and beyond', 'human resource management', \n",
    "                'housing unit estimates', 'international data base', 'labor market analysts', 'major land uses',\n",
    "                'mars exploration program', 'new residential construction', 'oxygen delivery system',\n",
    "                'pilot boarding areas', 'profiles in science', 'state fact sheets', 'summary of business',\n",
    "                'tsunamis general', 'virtual grower', # 0.620\n",
    "               ]\n",
    "wrong_names = [\n",
    "    'national assessment of educational progress',\n",
    "    'national postsecondary student aid study',\n",
    "    'nursing home compare',\n",
    "    'private school universe survey',\n",
    "    'program for international student assessment',\n",
    "    'progress in international reading literacy study',\n",
    "    'schools and staffing survey'\n",
    "]\n",
    "\n",
    "a = tmp8['ext_cleaned_label'].values\n",
    "b = []\n",
    "for l in tqdm(a):\n",
    "    sub_label = []\n",
    "    for l2 in l:\n",
    "        append_ = True\n",
    "        for l3 in not_datasets:\n",
    "            if l3 in l2:\n",
    "                append_ = False\n",
    "        if append_:\n",
    "            for wn in wrong_names:\n",
    "                if wn in l2:\n",
    "                    l2 = wn\n",
    "            sub_label.append(l2)\n",
    "    b.append(sub_label)\n",
    "tmp8['ext_cleaned_label2'] = b\n",
    "tmp8['ext_cleaned_label2'] = tmp8['ext_cleaned_label2'].apply(lambda x: np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "loose-kruger",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:50:14.129088Z",
     "iopub.status.busy": "2021-06-22T02:50:14.121761Z",
     "iopub.status.idle": "2021-06-22T02:50:14.137284Z",
     "shell.execute_reply": "2021-06-22T02:50:14.136499Z",
     "shell.execute_reply.started": "2021-06-22T02:39:28.785014Z"
    },
    "papermill": {
     "duration": 0.041679,
     "end_time": "2021-06-22T02:50:14.137405",
     "exception": false,
     "start_time": "2021-06-22T02:50:14.095726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14316\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>pub_title</th>\n",
       "      <th>dataset_title</th>\n",
       "      <th>dataset_label</th>\n",
       "      <th>cleaned_label</th>\n",
       "      <th>ext_cleaned_label</th>\n",
       "      <th>ext_cleaned_label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f70051bf-a763-415b-aa66-97ae57f2efc1</td>\n",
       "      <td>Analysis of groundwater response to tidal fluc...</td>\n",
       "      <td>NOAA Tide Gauge</td>\n",
       "      <td>NOAA tidal station</td>\n",
       "      <td>noaa tidal station</td>\n",
       "      <td>[noaa tidal station]</td>\n",
       "      <td>[noaa tidal station]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0d4e13ca-47ec-4827-b814-a39e5b8fede3</td>\n",
       "      <td>Geophysical and sampling data from the inner c...</td>\n",
       "      <td>NOAA Tide Gauge</td>\n",
       "      <td>NOAA tidal station</td>\n",
       "      <td>noaa tidal station</td>\n",
       "      <td>[noaa tidal station]</td>\n",
       "      <td>[noaa tidal station]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c5cf06e5-182f-4c33-bf15-e06a0d353efd</td>\n",
       "      <td>Geophysical and sampling data from the inner c...</td>\n",
       "      <td>NOAA Tide Gauge</td>\n",
       "      <td>NOAA tidal station</td>\n",
       "      <td>noaa tidal station</td>\n",
       "      <td>[gulf of maine, noaa tidal station]</td>\n",
       "      <td>[noaa tidal station]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>da25e497-208d-4ed5-9c51-37c69a5524d3</td>\n",
       "      <td>Development of the Hydrodynamic Model for Long...</td>\n",
       "      <td>NOAA Tide Gauge</td>\n",
       "      <td>NOAA tidal station</td>\n",
       "      <td>noaa tidal station</td>\n",
       "      <td>[noaa tidal station]</td>\n",
       "      <td>[noaa tidal station]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50d6879b-1c6b-4434-965e-19a7271e8c49</td>\n",
       "      <td>MODELING MICROBIAL WATER QUALITY AT A BEACH IM...</td>\n",
       "      <td>NOAA Tide Gauge</td>\n",
       "      <td>NOAA tidal station</td>\n",
       "      <td>noaa tidal station</td>\n",
       "      <td>[noaa tidal station]</td>\n",
       "      <td>[noaa tidal station]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  f70051bf-a763-415b-aa66-97ae57f2efc1   \n",
       "1  0d4e13ca-47ec-4827-b814-a39e5b8fede3   \n",
       "2  c5cf06e5-182f-4c33-bf15-e06a0d353efd   \n",
       "3  da25e497-208d-4ed5-9c51-37c69a5524d3   \n",
       "4  50d6879b-1c6b-4434-965e-19a7271e8c49   \n",
       "\n",
       "                                           pub_title    dataset_title  \\\n",
       "0  Analysis of groundwater response to tidal fluc...  NOAA Tide Gauge   \n",
       "1  Geophysical and sampling data from the inner c...  NOAA Tide Gauge   \n",
       "2  Geophysical and sampling data from the inner c...  NOAA Tide Gauge   \n",
       "3  Development of the Hydrodynamic Model for Long...  NOAA Tide Gauge   \n",
       "4  MODELING MICROBIAL WATER QUALITY AT A BEACH IM...  NOAA Tide Gauge   \n",
       "\n",
       "        dataset_label       cleaned_label  \\\n",
       "0  NOAA tidal station  noaa tidal station   \n",
       "1  NOAA tidal station  noaa tidal station   \n",
       "2  NOAA tidal station  noaa tidal station   \n",
       "3  NOAA tidal station  noaa tidal station   \n",
       "4  NOAA tidal station  noaa tidal station   \n",
       "\n",
       "                     ext_cleaned_label    ext_cleaned_label2  \n",
       "0                 [noaa tidal station]  [noaa tidal station]  \n",
       "1                 [noaa tidal station]  [noaa tidal station]  \n",
       "2  [gulf of maine, noaa tidal station]  [noaa tidal station]  \n",
       "3                 [noaa tidal station]  [noaa tidal station]  \n",
       "4                 [noaa tidal station]  [noaa tidal station]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = tmp8\n",
    "print(len(train))\n",
    "tmp8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "automotive-religion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:50:14.171523Z",
     "iopub.status.busy": "2021-06-22T02:50:14.170791Z",
     "iopub.status.idle": "2021-06-22T02:51:19.180666Z",
     "shell.execute_reply": "2021-06-22T02:51:19.180178Z",
     "shell.execute_reply.started": "2021-06-22T02:14:04.083255Z"
    },
    "papermill": {
     "duration": 65.028755,
     "end_time": "2021-06-22T02:51:19.180793",
     "exception": false,
     "start_time": "2021-06-22T02:50:14.152038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14316/14316 [01:04<00:00, 220.25it/s]\n"
     ]
    }
   ],
   "source": [
    "papers = {}\n",
    "for paper_id in tqdm(train['Id'].unique()):\n",
    "    with open(f'{paper_train_folder}/{paper_id}.json', 'r') as f:\n",
    "        paper = json.load(f)\n",
    "        papers[paper_id] = paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reasonable-postage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:51:19.526295Z",
     "iopub.status.busy": "2021-06-22T02:51:19.525569Z",
     "iopub.status.idle": "2021-06-22T02:51:19.528320Z",
     "shell.execute_reply": "2021-06-22T02:51:19.528729Z",
     "shell.execute_reply.started": "2021-06-22T02:44:45.111271Z"
    },
    "papermill": {
     "duration": 0.180014,
     "end_time": "2021-06-22T02:51:19.528884",
     "exception": false,
     "start_time": "2021-06-22T02:51:19.348870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_training_text(txt):\n",
    "    \"\"\"\n",
    "    similar to the default clean_text function but without lowercasing.\n",
    "    \"\"\"\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt)).strip()\n",
    "\n",
    "def shorten_sentences(sentences):\n",
    "    short_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        if len(words) > MAX_LENGTH:\n",
    "            for p in range(0, len(words), MAX_LENGTH - OVERLAP):\n",
    "                short_sentences.append(' '.join(words[p:p+MAX_LENGTH]))\n",
    "        else:\n",
    "            short_sentences.append(sentence)\n",
    "    return short_sentences\n",
    "\n",
    "def find_sublist(big_list, small_list):\n",
    "    all_positions = []\n",
    "    for i in range(len(big_list) - len(small_list) + 1):\n",
    "        \n",
    "        big_list = [x.lower() for x in big_list]\n",
    "        \n",
    "        if small_list == big_list[i:i+len(small_list)]:\n",
    "            all_positions.append(i)\n",
    "    \n",
    "    return all_positions\n",
    "\n",
    "def tag_sentence(sentence, labels): # requirement: both sentence and labels are already cleaned\n",
    "    sentence_words = sentence.split()\n",
    "    \n",
    "    if labels is not None and any(re.findall(f'\\\\b{label}\\\\b', sentence.lower())\n",
    "                                  for label in labels): # positive sample\n",
    "        nes = ['O'] * len(sentence_words)\n",
    "        for label in labels:\n",
    "            label_words = label.split()\n",
    "\n",
    "            all_pos = find_sublist(sentence_words, label_words)\n",
    "            for pos in all_pos:\n",
    "                nes[pos] = 'B'\n",
    "                for i in range(pos+1, pos+len(label_words)):\n",
    "                    nes[i] = 'I'\n",
    "\n",
    "        return True, list(zip(sentence_words, nes))\n",
    "        \n",
    "    else: # negative sample\n",
    "        nes = ['O'] * len(sentence_words)\n",
    "        return False, list(zip(sentence_words, nes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opposite-artwork",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:51:19.887235Z",
     "iopub.status.busy": "2021-06-22T02:51:19.886394Z",
     "iopub.status.idle": "2021-06-22T02:54:30.614046Z",
     "shell.execute_reply": "2021-06-22T02:54:30.613167Z",
     "shell.execute_reply.started": "2021-06-22T02:44:46.599105Z"
    },
    "papermill": {
     "duration": 190.906466,
     "end_time": "2021-06-22T02:54:30.614187",
     "exception": false,
     "start_time": "2021-06-22T02:51:19.707721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt_pos, cnt_neg = 0, 0 # number of sentences that contain/not contain labels\n",
    "ner_data = []\n",
    "\n",
    "# pbar = tqdm(total=len(train))\n",
    "for i, id, dataset_label in train[['Id', 'ext_cleaned_label2']].itertuples():\n",
    "    # paper\n",
    "    paper = papers[id]\n",
    "    \n",
    "    # labels\n",
    "#     labels = dataset_label.split('|')\n",
    "#     labels = [clean_training_text(label) for label in labels]\n",
    "    labels = dataset_label\n",
    "    \n",
    "    # sentences\n",
    "    sentences = set([clean_training_text(sentence) for section in paper \n",
    "                 for sentence in section['text'].split('.') \n",
    "                ])\n",
    "    sentences = shorten_sentences(sentences) # make sentences short\n",
    "    sentences = [sentence for sentence in sentences if len(sentence) > 10] # only accept sentences with length > 10 chars\n",
    "    \n",
    "    # positive sample\n",
    "    for sentence in sentences:\n",
    "        is_positive, tags = tag_sentence(sentence, labels)\n",
    "        if is_positive:\n",
    "            cnt_pos += 1\n",
    "            ner_data.append(tags)\n",
    "        elif any(word in sentence for word in ['data', 'study', 'from']): \n",
    "            if np.random.rand(1)[0] > 0.6:\n",
    "                ner_data.append(tags)\n",
    "                cnt_neg += 1\n",
    "    \n",
    "    # process bar\n",
    "#     pbar.update(1)\n",
    "#     pbar.set_description(f\"Training data size: {cnt_pos} positives + {cnt_neg} negatives\")\n",
    "\n",
    "# shuffling\n",
    "random.shuffle(ner_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "enhanced-intermediate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:54:30.952206Z",
     "iopub.status.busy": "2021-06-22T02:54:30.951600Z",
     "iopub.status.idle": "2021-06-22T02:54:30.954606Z",
     "shell.execute_reply": "2021-06-22T02:54:30.955001Z",
     "shell.execute_reply.started": "2021-06-22T02:47:59.039804Z"
    },
    "papermill": {
     "duration": 0.173564,
     "end_time": "2021-06-22T02:54:30.955136",
     "exception": false,
     "start_time": "2021-06-22T02:54:30.781572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 58999 positives + 332724 negatives\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data size: {cnt_pos} positives + {cnt_neg} negatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "floating-criticism",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:54:31.299124Z",
     "iopub.status.busy": "2021-06-22T02:54:31.289956Z",
     "iopub.status.idle": "2021-06-22T02:54:51.769207Z",
     "shell.execute_reply": "2021-06-22T02:54:51.768264Z",
     "shell.execute_reply.started": "2021-06-21T22:48:52.151608Z"
    },
    "papermill": {
     "duration": 20.649405,
     "end_time": "2021-06-22T02:54:51.769351",
     "exception": false,
     "start_time": "2021-06-22T02:54:31.119946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('train_ner.json', 'w') as f:\n",
    "    for row in ner_data: \n",
    "        words, nes = list(zip(*row))\n",
    "        row_json = {'tokens' : words, 'tags' : nes}\n",
    "        json.dump(row_json, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ahead-intake",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T02:54:52.144060Z",
     "iopub.status.busy": "2021-06-22T02:54:52.116115Z",
     "iopub.status.idle": "2021-06-22T05:48:25.925415Z",
     "shell.execute_reply": "2021-06-22T05:48:25.924605Z",
     "shell.execute_reply.started": "2021-06-21T22:48:58.140553Z"
    },
    "papermill": {
     "duration": 10413.983064,
     "end_time": "2021-06-22T05:48:25.925615",
     "exception": false,
     "start_time": "2021-06-22T02:54:51.942551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-22 02:54:56.347750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n",
      "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-f7b38428ba224caf/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\r\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-f7b38428ba224caf/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\r\n",
      "[INFO|file_utils.py:1402] 2021-06-22 02:55:20,150 >> https://huggingface.co/xlm-roberta-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpvjtsu9pw\r\n",
      "Downloading: 100%|██████████████████████████████| 512/512 [00:00<00:00, 403kB/s]\r\n",
      "[INFO|file_utils.py:1406] 2021-06-22 02:55:20,646 >> storing https://huggingface.co/xlm-roberta-base/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.ab95cf27f9419a99cce4f19d09e655aba382a2bafe2fe26d0cc24c18cf1a1af6\r\n",
      "[INFO|file_utils.py:1409] 2021-06-22 02:55:20,646 >> creating metadata file for /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.ab95cf27f9419a99cce4f19d09e655aba382a2bafe2fe26d0cc24c18cf1a1af6\r\n",
      "[INFO|configuration_utils.py:472] 2021-06-22 02:55:20,647 >> loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.ab95cf27f9419a99cce4f19d09e655aba382a2bafe2fe26d0cc24c18cf1a1af6\r\n",
      "[INFO|configuration_utils.py:508] 2021-06-22 02:55:20,648 >> Model config XLMRobertaConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"XLMRobertaForMaskedLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"bos_token_id\": 0,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"finetuning_task\": \"ner\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 768,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\"\r\n",
      "  },\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2\r\n",
      "  },\r\n",
      "  \"layer_norm_eps\": 1e-05,\r\n",
      "  \"max_position_embeddings\": 514,\r\n",
      "  \"model_type\": \"xlm-roberta\",\r\n",
      "  \"num_attention_heads\": 12,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 1,\r\n",
      "  \"position_embedding_type\": \"absolute\",\r\n",
      "  \"transformers_version\": \"4.5.0.dev0\",\r\n",
      "  \"type_vocab_size\": 1,\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 250002\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|configuration_utils.py:472] 2021-06-22 02:55:21,141 >> loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.ab95cf27f9419a99cce4f19d09e655aba382a2bafe2fe26d0cc24c18cf1a1af6\r\n",
      "[INFO|configuration_utils.py:508] 2021-06-22 02:55:21,142 >> Model config XLMRobertaConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"XLMRobertaForMaskedLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"bos_token_id\": 0,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 768,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"layer_norm_eps\": 1e-05,\r\n",
      "  \"max_position_embeddings\": 514,\r\n",
      "  \"model_type\": \"xlm-roberta\",\r\n",
      "  \"num_attention_heads\": 12,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 1,\r\n",
      "  \"position_embedding_type\": \"absolute\",\r\n",
      "  \"transformers_version\": \"4.5.0.dev0\",\r\n",
      "  \"type_vocab_size\": 1,\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 250002\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|file_utils.py:1402] 2021-06-22 02:55:21,629 >> https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpyognqpow\r\n",
      "Downloading: 100%|█████████████████████████| 5.07M/5.07M [00:00<00:00, 7.67MB/s]\r\n",
      "[INFO|file_utils.py:1406] 2021-06-22 02:55:22,840 >> storing https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model in cache at /root/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\r\n",
      "[INFO|file_utils.py:1409] 2021-06-22 02:55:22,840 >> creating metadata file for /root/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\r\n",
      "[INFO|file_utils.py:1402] 2021-06-22 02:55:23,344 >> https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwfmju8xx\r\n",
      "Downloading: 100%|█████████████████████████| 9.10M/9.10M [00:00<00:00, 12.4MB/s]\r\n",
      "[INFO|file_utils.py:1406] 2021-06-22 02:55:24,659 >> storing https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\r\n",
      "[INFO|file_utils.py:1409] 2021-06-22 02:55:24,659 >> creating metadata file for /root/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\r\n",
      "[INFO|tokenization_utils_base.py:1702] 2021-06-22 02:55:26,153 >> loading file https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model from cache at /root/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\r\n",
      "[INFO|tokenization_utils_base.py:1702] 2021-06-22 02:55:26,153 >> loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\r\n",
      "[INFO|tokenization_utils_base.py:1702] 2021-06-22 02:55:26,153 >> loading file https://huggingface.co/xlm-roberta-base/resolve/main/added_tokens.json from cache at None\r\n",
      "[INFO|tokenization_utils_base.py:1702] 2021-06-22 02:55:26,153 >> loading file https://huggingface.co/xlm-roberta-base/resolve/main/special_tokens_map.json from cache at None\r\n",
      "[INFO|tokenization_utils_base.py:1702] 2021-06-22 02:55:26,153 >> loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json from cache at None\r\n",
      "[INFO|file_utils.py:1402] 2021-06-22 02:55:27,244 >> https://huggingface.co/xlm-roberta-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp52f43118\r\n",
      "Downloading: 100%|█████████████████████████| 1.12G/1.12G [01:34<00:00, 11.8MB/s]\r\n",
      "[INFO|file_utils.py:1406] 2021-06-22 02:57:02,978 >> storing https://huggingface.co/xlm-roberta-base/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2\r\n",
      "[INFO|file_utils.py:1409] 2021-06-22 02:57:02,978 >> creating metadata file for /root/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2\r\n",
      "[INFO|modeling_utils.py:1051] 2021-06-22 02:57:02,979 >> loading weights file https://huggingface.co/xlm-roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2\r\n",
      "[WARNING|modeling_utils.py:1159] 2021-06-22 02:57:11,790 >> Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\r\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n",
      "[WARNING|modeling_utils.py:1170] 2021-06-22 02:57:11,790 >> Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "100%|█████████████████████████████████████████| 392/392 [01:41<00:00,  3.85ba/s]\r\n",
      "[INFO|trainer.py:485] 2021-06-22 02:59:00,549 >> The following columns in the training set  don't have a corresponding argument in `XLMRobertaForTokenClassification.forward` and have been ignored: tags, tokens.\r\n",
      "[INFO|trainer.py:988] 2021-06-22 02:59:00,863 >> ***** Running training *****\r\n",
      "[INFO|trainer.py:989] 2021-06-22 02:59:00,863 >>   Num examples = 391723\r\n",
      "[INFO|trainer.py:990] 2021-06-22 02:59:00,864 >>   Num Epochs = 1\r\n",
      "[INFO|trainer.py:991] 2021-06-22 02:59:00,864 >>   Instantaneous batch size per device = 8\r\n",
      "[INFO|trainer.py:992] 2021-06-22 02:59:00,864 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\r\n",
      "[INFO|trainer.py:993] 2021-06-22 02:59:00,864 >>   Gradient Accumulation steps = 1\r\n",
      "[INFO|trainer.py:994] 2021-06-22 02:59:00,864 >>   Total optimization steps = 48966\r\n",
      "{'loss': 0.055, 'learning_rate': 4.9489441653392155e-05, 'epoch': 0.01}\r\n",
      "{'loss': 0.0289, 'learning_rate': 4.89788833067843e-05, 'epoch': 0.02}\r\n",
      "{'loss': 0.0167, 'learning_rate': 4.8468324960176454e-05, 'epoch': 0.03}\r\n",
      "{'loss': 0.0155, 'learning_rate': 4.79577666135686e-05, 'epoch': 0.04}\r\n",
      "{'loss': 0.0149, 'learning_rate': 4.7447208266960754e-05, 'epoch': 0.05}\r\n",
      "{'loss': 0.0153, 'learning_rate': 4.69366499203529e-05, 'epoch': 0.06}\r\n",
      "{'loss': 0.0139, 'learning_rate': 4.642609157374505e-05, 'epoch': 0.07}\r\n",
      "{'loss': 0.012, 'learning_rate': 4.59155332271372e-05, 'epoch': 0.08}\r\n",
      "{'loss': 0.0105, 'learning_rate': 4.540497488052935e-05, 'epoch': 0.09}\r\n",
      "{'loss': 0.012, 'learning_rate': 4.48944165339215e-05, 'epoch': 0.1}\r\n",
      "{'loss': 0.0118, 'learning_rate': 4.438385818731365e-05, 'epoch': 0.11}\r\n",
      "{'loss': 0.0132, 'learning_rate': 4.3873299840705804e-05, 'epoch': 0.12}\r\n",
      "{'loss': 0.0108, 'learning_rate': 4.336274149409795e-05, 'epoch': 0.13}\r\n",
      "{'loss': 0.0094, 'learning_rate': 4.2852183147490096e-05, 'epoch': 0.14}\r\n",
      "{'loss': 0.0102, 'learning_rate': 4.234162480088225e-05, 'epoch': 0.15}\r\n",
      "{'loss': 0.0105, 'learning_rate': 4.1831066454274395e-05, 'epoch': 0.16}\r\n",
      "{'loss': 0.0078, 'learning_rate': 4.132050810766654e-05, 'epoch': 0.17}\r\n",
      "{'loss': 0.0097, 'learning_rate': 4.0809949761058694e-05, 'epoch': 0.18}\r\n",
      "{'loss': 0.0085, 'learning_rate': 4.029939141445084e-05, 'epoch': 0.19}\r\n",
      "{'loss': 0.0071, 'learning_rate': 3.978883306784299e-05, 'epoch': 0.2}\r\n",
      "{'loss': 0.0082, 'learning_rate': 3.927827472123514e-05, 'epoch': 0.21}\r\n",
      "{'loss': 0.0096, 'learning_rate': 3.876771637462729e-05, 'epoch': 0.22}\r\n",
      "{'loss': 0.0071, 'learning_rate': 3.8257158028019445e-05, 'epoch': 0.23}\r\n",
      "{'loss': 0.0083, 'learning_rate': 3.774659968141159e-05, 'epoch': 0.25}\r\n",
      "{'loss': 0.0095, 'learning_rate': 3.7236041334803744e-05, 'epoch': 0.26}\r\n",
      "{'loss': 0.01, 'learning_rate': 3.672548298819589e-05, 'epoch': 0.27}\r\n",
      "{'loss': 0.0145, 'learning_rate': 3.6214924641588044e-05, 'epoch': 0.28}\r\n",
      "{'loss': 0.0112, 'learning_rate': 3.570436629498019e-05, 'epoch': 0.29}\r\n",
      "{'loss': 0.0109, 'learning_rate': 3.519380794837234e-05, 'epoch': 0.3}\r\n",
      "{'loss': 0.0393, 'learning_rate': 3.468324960176449e-05, 'epoch': 0.31}\r\n",
      " 31%|██████████▋                        | 15000/48966 [51:52<1:51:32,  5.08it/s][INFO|trainer.py:1600] 2021-06-22 03:50:53,505 >> Saving model checkpoint to ./output/checkpoint-15000\r\n",
      "[INFO|configuration_utils.py:318] 2021-06-22 03:50:53,507 >> Configuration saved in ./output/checkpoint-15000/config.json\r\n",
      "[INFO|modeling_utils.py:837] 2021-06-22 03:50:58,418 >> Model weights saved in ./output/checkpoint-15000/pytorch_model.bin\r\n",
      "[INFO|tokenization_utils_base.py:1896] 2021-06-22 03:50:58,419 >> tokenizer config file saved in ./output/checkpoint-15000/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:1902] 2021-06-22 03:50:58,419 >> Special tokens file saved in ./output/checkpoint-15000/special_tokens_map.json\r\n",
      "{'loss': 0.0388, 'learning_rate': 3.417269125515664e-05, 'epoch': 0.32}\r\n",
      "{'loss': 0.0245, 'learning_rate': 3.366213290854879e-05, 'epoch': 0.33}\r\n",
      "{'loss': 0.0138, 'learning_rate': 3.315157456194094e-05, 'epoch': 0.34}\r\n",
      "{'loss': 0.0094, 'learning_rate': 3.2641016215333094e-05, 'epoch': 0.35}\r\n",
      "{'loss': 0.0106, 'learning_rate': 3.213045786872524e-05, 'epoch': 0.36}\r\n",
      "{'loss': 0.0094, 'learning_rate': 3.161989952211739e-05, 'epoch': 0.37}\r\n",
      "{'loss': 0.0087, 'learning_rate': 3.110934117550954e-05, 'epoch': 0.38}\r\n",
      "{'loss': 0.0103, 'learning_rate': 3.059878282890169e-05, 'epoch': 0.39}\r\n",
      "{'loss': 0.0096, 'learning_rate': 3.0088224482293835e-05, 'epoch': 0.4}\r\n",
      "{'loss': 0.0097, 'learning_rate': 2.9577666135685988e-05, 'epoch': 0.41}\r\n",
      "{'loss': 0.0091, 'learning_rate': 2.9067107789078134e-05, 'epoch': 0.42}\r\n",
      "{'loss': 0.0078, 'learning_rate': 2.8556549442470287e-05, 'epoch': 0.43}\r\n",
      "{'loss': 0.0082, 'learning_rate': 2.8045991095862433e-05, 'epoch': 0.44}\r\n",
      "{'loss': 0.0068, 'learning_rate': 2.7535432749254586e-05, 'epoch': 0.45}\r\n",
      "{'loss': 0.0103, 'learning_rate': 2.702487440264674e-05, 'epoch': 0.46}\r\n",
      "{'loss': 0.0098, 'learning_rate': 2.6514316056038885e-05, 'epoch': 0.47}\r\n",
      "{'loss': 0.007, 'learning_rate': 2.6003757709431038e-05, 'epoch': 0.48}\r\n",
      "{'loss': 0.0056, 'learning_rate': 2.5493199362823184e-05, 'epoch': 0.49}\r\n",
      "{'loss': 0.007, 'learning_rate': 2.4982641016215334e-05, 'epoch': 0.5}\r\n",
      "{'loss': 0.0074, 'learning_rate': 2.4472082669607487e-05, 'epoch': 0.51}\r\n",
      "{'loss': 0.0065, 'learning_rate': 2.3961524322999636e-05, 'epoch': 0.52}\r\n",
      "{'loss': 0.0076, 'learning_rate': 2.3450965976391782e-05, 'epoch': 0.53}\r\n",
      "{'loss': 0.0071, 'learning_rate': 2.2940407629783932e-05, 'epoch': 0.54}\r\n",
      "{'loss': 0.0067, 'learning_rate': 2.242984928317608e-05, 'epoch': 0.55}\r\n",
      "{'loss': 0.0074, 'learning_rate': 2.191929093656823e-05, 'epoch': 0.56}\r\n",
      "{'loss': 0.0096, 'learning_rate': 2.140873258996038e-05, 'epoch': 0.57}\r\n",
      "{'loss': 0.0056, 'learning_rate': 2.089817424335253e-05, 'epoch': 0.58}\r\n",
      "{'loss': 0.0064, 'learning_rate': 2.038761589674468e-05, 'epoch': 0.59}\r\n",
      "{'loss': 0.0074, 'learning_rate': 1.987705755013683e-05, 'epoch': 0.6}\r\n",
      "{'loss': 0.0053, 'learning_rate': 1.936649920352898e-05, 'epoch': 0.61}\r\n",
      " 61%|████████████████████▏            | 30000/48966 [1:43:30<1:10:42,  4.47it/s][INFO|trainer.py:1600] 2021-06-22 04:42:31,094 >> Saving model checkpoint to ./output/checkpoint-30000\r\n",
      "[INFO|configuration_utils.py:318] 2021-06-22 04:42:31,095 >> Configuration saved in ./output/checkpoint-30000/config.json\r\n",
      "[INFO|modeling_utils.py:837] 2021-06-22 04:42:36,150 >> Model weights saved in ./output/checkpoint-30000/pytorch_model.bin\r\n",
      "[INFO|tokenization_utils_base.py:1896] 2021-06-22 04:42:36,154 >> tokenizer config file saved in ./output/checkpoint-30000/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:1902] 2021-06-22 04:42:36,154 >> Special tokens file saved in ./output/checkpoint-30000/special_tokens_map.json\r\n",
      "{'loss': 0.0043, 'learning_rate': 1.885594085692113e-05, 'epoch': 0.62}\r\n",
      "{'loss': 0.0059, 'learning_rate': 1.834538251031328e-05, 'epoch': 0.63}\r\n",
      "{'loss': 0.0069, 'learning_rate': 1.783482416370543e-05, 'epoch': 0.64}\r\n",
      "{'loss': 0.0047, 'learning_rate': 1.732426581709758e-05, 'epoch': 0.65}\r\n",
      "{'loss': 0.0041, 'learning_rate': 1.681370747048973e-05, 'epoch': 0.66}\r\n",
      "{'loss': 0.0044, 'learning_rate': 1.630314912388188e-05, 'epoch': 0.67}\r\n",
      "{'loss': 0.0046, 'learning_rate': 1.579259077727403e-05, 'epoch': 0.68}\r\n",
      "{'loss': 0.0054, 'learning_rate': 1.5282032430666175e-05, 'epoch': 0.69}\r\n",
      "{'loss': 0.0041, 'learning_rate': 1.4771474084058326e-05, 'epoch': 0.7}\r\n",
      "{'loss': 0.0055, 'learning_rate': 1.4260915737450476e-05, 'epoch': 0.71}\r\n",
      "{'loss': 0.0044, 'learning_rate': 1.3750357390842627e-05, 'epoch': 0.72}\r\n",
      "{'loss': 0.0038, 'learning_rate': 1.3239799044234777e-05, 'epoch': 0.74}\r\n",
      "{'loss': 0.0058, 'learning_rate': 1.2729240697626926e-05, 'epoch': 0.75}\r\n",
      "{'loss': 0.0035, 'learning_rate': 1.2218682351019076e-05, 'epoch': 0.76}\r\n",
      "{'loss': 0.004, 'learning_rate': 1.1708124004411225e-05, 'epoch': 0.77}\r\n",
      "{'loss': 0.0035, 'learning_rate': 1.1197565657803375e-05, 'epoch': 0.78}\r\n",
      "{'loss': 0.0057, 'learning_rate': 1.0687007311195524e-05, 'epoch': 0.79}\r\n",
      "{'loss': 0.0053, 'learning_rate': 1.0176448964587674e-05, 'epoch': 0.8}\r\n",
      "{'loss': 0.0059, 'learning_rate': 9.665890617979823e-06, 'epoch': 0.81}\r\n",
      "{'loss': 0.0039, 'learning_rate': 9.155332271371973e-06, 'epoch': 0.82}\r\n",
      "{'loss': 0.0046, 'learning_rate': 8.644773924764122e-06, 'epoch': 0.83}\r\n",
      "{'loss': 0.0042, 'learning_rate': 8.134215578156272e-06, 'epoch': 0.84}\r\n",
      "{'loss': 0.0023, 'learning_rate': 7.6236572315484216e-06, 'epoch': 0.85}\r\n",
      "{'loss': 0.005, 'learning_rate': 7.113098884940571e-06, 'epoch': 0.86}\r\n",
      "{'loss': 0.0026, 'learning_rate': 6.6025405383327215e-06, 'epoch': 0.87}\r\n",
      "{'loss': 0.0048, 'learning_rate': 6.091982191724871e-06, 'epoch': 0.88}\r\n",
      "{'loss': 0.002, 'learning_rate': 5.581423845117021e-06, 'epoch': 0.89}\r\n",
      "{'loss': 0.0035, 'learning_rate': 5.070865498509169e-06, 'epoch': 0.9}\r\n",
      "{'loss': 0.0026, 'learning_rate': 4.56030715190132e-06, 'epoch': 0.91}\r\n",
      "{'loss': 0.0038, 'learning_rate': 4.049748805293469e-06, 'epoch': 0.92}\r\n",
      " 92%|████████████████████████████████▏  | 45000/48966 [2:35:20<13:14,  4.99it/s][INFO|trainer.py:1600] 2021-06-22 05:34:21,721 >> Saving model checkpoint to ./output/checkpoint-45000\r\n",
      "[INFO|configuration_utils.py:318] 2021-06-22 05:34:21,723 >> Configuration saved in ./output/checkpoint-45000/config.json\r\n",
      "[INFO|modeling_utils.py:837] 2021-06-22 05:34:30,979 >> Model weights saved in ./output/checkpoint-45000/pytorch_model.bin\r\n",
      "[INFO|tokenization_utils_base.py:1896] 2021-06-22 05:34:30,980 >> tokenizer config file saved in ./output/checkpoint-45000/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:1902] 2021-06-22 05:34:30,980 >> Special tokens file saved in ./output/checkpoint-45000/special_tokens_map.json\r\n",
      "{'loss': 0.0035, 'learning_rate': 3.5391904586856184e-06, 'epoch': 0.93}\r\n",
      "{'loss': 0.0047, 'learning_rate': 3.0286321120777683e-06, 'epoch': 0.94}\r\n",
      "{'loss': 0.0023, 'learning_rate': 2.518073765469918e-06, 'epoch': 0.95}\r\n",
      "{'loss': 0.0044, 'learning_rate': 2.007515418862068e-06, 'epoch': 0.96}\r\n",
      "{'loss': 0.0043, 'learning_rate': 1.4969570722542172e-06, 'epoch': 0.97}\r\n",
      "{'loss': 0.0032, 'learning_rate': 9.86398725646367e-07, 'epoch': 0.98}\r\n",
      "{'loss': 0.0045, 'learning_rate': 4.758403790385165e-07, 'epoch': 0.99}\r\n",
      "100%|███████████████████████████████████| 48966/48966 [2:49:17<00:00,  4.93it/s][INFO|trainer.py:1171] 2021-06-22 05:48:18,511 >> \r\n",
      "\r\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\r\n",
      "\r\n",
      "\r\n",
      "{'train_runtime': 10157.6476, 'train_samples_per_second': 4.821, 'epoch': 1.0}\r\n",
      "100%|███████████████████████████████████| 48966/48966 [2:49:17<00:00,  4.82it/s]\r\n",
      "[INFO|trainer.py:1600] 2021-06-22 05:48:18,733 >> Saving model checkpoint to ./output\r\n",
      "[INFO|configuration_utils.py:318] 2021-06-22 05:48:18,736 >> Configuration saved in ./output/config.json\r\n",
      "[INFO|modeling_utils.py:837] 2021-06-22 05:48:23,251 >> Model weights saved in ./output/pytorch_model.bin\r\n",
      "[INFO|tokenization_utils_base.py:1896] 2021-06-22 05:48:23,254 >> tokenizer config file saved in ./output/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:1902] 2021-06-22 05:48:23,254 >> Special tokens file saved in ./output/special_tokens_map.json\r\n",
      "[INFO|trainer_pt_utils.py:735] 2021-06-22 05:48:23,729 >> ***** train metrics *****\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,729 >>   epoch                      =        1.0\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,729 >>   init_mem_cpu_alloc_delta   =      995MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,729 >>   init_mem_cpu_peaked_delta  =      930MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,729 >>   init_mem_gpu_alloc_delta   =     1058MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,729 >>   init_mem_gpu_peaked_delta  =        0MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,729 >>   train_mem_cpu_alloc_delta  =      130MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,730 >>   train_mem_cpu_peaked_delta =     2439MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,730 >>   train_mem_gpu_alloc_delta  =     3188MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,730 >>   train_mem_gpu_peaked_delta =     1796MB\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,730 >>   train_runtime              = 2:49:17.64\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,730 >>   train_samples              =     391723\r\n",
      "[INFO|trainer_pt_utils.py:740] 2021-06-22 05:48:23,730 >>   train_samples_per_second   =      4.821\r\n"
     ]
    }
   ],
   "source": [
    "!python ../input/kaggle-ner-utils/kaggle_run_ner.py \\\n",
    "--model_name_or_path 'xlm-roberta-base' \\\n",
    "--train_file './train_ner.json' \\\n",
    "--validation_file './train_ner.json' \\\n",
    "--num_train_epochs 1 \\\n",
    "--per_device_train_batch_size 8 \\\n",
    "--per_device_eval_batch_size 8 \\\n",
    "--save_steps 15000 \\\n",
    "--output_dir './output' \\\n",
    "--report_to 'none' \\\n",
    "--seed 123 \\\n",
    "--do_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-cable",
   "metadata": {
    "papermill": {
     "duration": 13.638337,
     "end_time": "2021-06-22T05:48:53.182946",
     "exception": false,
     "start_time": "2021-06-22T05:48:39.544609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10778.184884,
   "end_time": "2021-06-22T05:49:09.153598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-22T02:49:30.968714",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
